{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import pandas as pd\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","import re\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')                     # Check for GPU availability\n","print(f\"Using device: {device}\")\n","\n","df = pd.read_csv(\"/content/poems-100.csv\")                                                  # Load the CSV file\n","poems = df[\"text\"].tolist()\n","\n","def preprocess_text(text):                                                                 # Preprocess the poems\n","    text = re.sub(r'[^\\w\\s]', '', text).lower()\n","    return text\n","processed_poems = [preprocess_text(poem) for poem in poems]"],"metadata":{"id":"ddL_mIFsghk_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"80ba5605-6a5c-4922-e418-f48a5d7a9d23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["\n","words = []                                                                             #tokenization\n","for poem in processed_poems:\n","    words.extend(poem.split())\n","\n","vocab = sorted(list(set(words)))\n","word_to_idx = {w: i for i, w in enumerate(vocab)}\n","idx_to_word = {i: w for i, w in enumerate(vocab)}\n","\n","vocab_size = len(vocab)\n","\n","\n","sequence_length = 10\n","sequences = []                                                                       # creating sequences\n","next_words = []\n","\n","for poem in processed_poems:\n","    poem_words = poem.split()\n","    if len(poem_words) > sequence_length:\n","        for i in range(len(poem_words) - sequence_length):\n","            seq = poem_words[i:i + sequence_length]\n","            next_word = poem_words[i + sequence_length]\n","            sequences.append([word_to_idx[word] for word in seq])\n","            next_words.append(word_to_idx[next_word])\n","\n","sequences = torch.tensor(sequences, dtype=torch.long).to(device)\n","next_words = torch.tensor(next_words, dtype=torch.long).to(device)"],"metadata":{"id":"lLMe3a_QgmO4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["                                                                                   # Dataset and DataLoader\n","class PoemDataset(Dataset):\n","    def __init__(self, sequences, next_words):\n","        self.sequences = sequences\n","        self.next_words = next_words\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        return self.sequences[idx], self.next_words[idx]\n","\n","dataset = PoemDataset(sequences, next_words)\n","dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"],"metadata":{"id":"RXDUu0M1gqgF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class PoemGenerator(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n","        super(PoemGenerator, self).__init__()                                                   # LSTM Model\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, vocab_size)\n","\n","    def forward(self, x):\n","        embedded = self.embedding(x)\n","        lstm_out, _ = self.lstm(embedded)\n","        output = self.fc(lstm_out[:, -1, :])\n","        return output\n","\n","# Hyperparameters\n","embedding_dim = 256\n","hidden_dim = 512\n","num_layers = 2\n","learning_rate = 0.001\n","epochs = 50\n","\n","# Initialize the model\n","model = PoemGenerator(vocab_size, embedding_dim, hidden_dim, num_layers).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"BN_SMKTFgu2c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training loop\n","for epoch in range(epochs):\n","    for sequences_batch, next_words_batch in dataloader:\n","        optimizer.zero_grad()\n","        outputs = model(sequences_batch)\n","        loss = criterion(outputs, next_words_batch)\n","        loss.backward()\n","        optimizer.step()\n","    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")"],"metadata":{"id":"10_9QLo_gybS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"254fe24f-c82b-4024-e08e-9cc48de0c186"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Loss: 6.881255149841309\n","Epoch 2/50, Loss: 6.124566078186035\n","Epoch 3/50, Loss: 5.903942584991455\n","Epoch 4/50, Loss: 5.898273944854736\n","Epoch 5/50, Loss: 5.5926432609558105\n","Epoch 6/50, Loss: 5.261765003204346\n","Epoch 7/50, Loss: 3.9703052043914795\n","Epoch 8/50, Loss: 4.019341468811035\n","Epoch 9/50, Loss: 2.810356616973877\n","Epoch 10/50, Loss: 2.3594794273376465\n","Epoch 11/50, Loss: 2.072136402130127\n","Epoch 12/50, Loss: 1.1919063329696655\n","Epoch 13/50, Loss: 0.6759076118469238\n","Epoch 14/50, Loss: 0.31448376178741455\n","Epoch 15/50, Loss: 0.14604800939559937\n","Epoch 16/50, Loss: 0.13865341246128082\n","Epoch 17/50, Loss: 0.053810011595487595\n","Epoch 18/50, Loss: 0.030310017988085747\n","Epoch 19/50, Loss: 0.026247665286064148\n","Epoch 20/50, Loss: 0.01926218718290329\n","Epoch 21/50, Loss: 0.016236403957009315\n","Epoch 22/50, Loss: 0.014221230521798134\n","Epoch 23/50, Loss: 0.012474690563976765\n","Epoch 24/50, Loss: 0.010696305893361568\n","Epoch 25/50, Loss: 0.008253064937889576\n","Epoch 26/50, Loss: 0.007077009417116642\n","Epoch 27/50, Loss: 0.004872445482760668\n","Epoch 28/50, Loss: 0.005242615006864071\n","Epoch 29/50, Loss: 0.005118104163557291\n","Epoch 30/50, Loss: 0.004052562639117241\n","Epoch 31/50, Loss: 0.0036130244843661785\n","Epoch 32/50, Loss: 0.0030391414184123278\n","Epoch 33/50, Loss: 0.0026552171912044287\n","Epoch 34/50, Loss: 0.0026729865930974483\n","Epoch 35/50, Loss: 0.002236430998891592\n","Epoch 36/50, Loss: 0.0018952653044834733\n","Epoch 37/50, Loss: 0.0016204582061618567\n","Epoch 38/50, Loss: 0.0013937775511294603\n","Epoch 39/50, Loss: 0.001336324610747397\n","Epoch 40/50, Loss: 0.001167357200756669\n","Epoch 41/50, Loss: 0.001069921418093145\n","Epoch 42/50, Loss: 0.0010141294915229082\n","Epoch 43/50, Loss: 0.0008211619569920003\n","Epoch 44/50, Loss: 0.0007982631796039641\n","Epoch 45/50, Loss: 0.0007313023670576513\n","Epoch 46/50, Loss: 0.0006129011744633317\n","Epoch 47/50, Loss: 0.0006009669741615653\n","Epoch 48/50, Loss: 0.0005366378463804722\n","Epoch 49/50, Loss: 0.0004747148195747286\n","Epoch 50/50, Loss: 0.0004367862129583955\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kYDBieHDgaIF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1deb421b-a404-4134-9bf0-627b7e1f0524"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generated Poem:\n"," city the candle tickets take anchor whirr\n","or words colter commanding bends a turnpike\n","rye seat trapper in words that nothing\n","has retiring see shaken breed call health\n","swimmers dates say mortars nudge vines angry\n","mould completes the hairy destiny beg companion\n","betwixt four autumn keep volumes spread lit\n","muscular\n"]}],"source":["import random\n","def generate_poem(model, start_word, word_to_idx, idx_to_word, device, length=50):\n","    model.eval()\n","    generated_poem = [start_word]\n","    input_seq = torch.tensor([[word_to_idx[start_word]]], dtype=torch.long).to(device)\n","\n","    with torch.no_grad():\n","        for _ in range(length - 1):\n","            output = model(input_seq)\n","            probabilities = torch.softmax(output, dim=1).cpu().numpy()[0] #get probability distribution\n","            predicted_word_idx = random.choices(range(len(probabilities)), weights=probabilities, k=1)[0] # sample from the distribution.\n","            predicted_word = idx_to_word[predicted_word_idx]\n","            generated_poem.append(predicted_word)\n","            input_seq = torch.tensor([[predicted_word_idx]], dtype=torch.long).to(device)\n","\n","\n","    formatted_poem = \"\"                                      #  Format the poem into multiple lines\n","    line = []\n","    word_count = 0\n","    for word in generated_poem:\n","        line.append(word)\n","        word_count += 1\n","        if word_count >= 7:\n","            formatted_poem += \" \".join(line) + \"\\n\"\n","            line = []\n","            word_count = 0\n","    if line:  # Add any remaining words\n","        formatted_poem += \" \".join(line)\n","    return formatted_poem\n","\n","\n","start_word = \"city\"\n","generated_poem = generate_poem(model, start_word, word_to_idx, idx_to_word, device)\n","print(\"Generated Poem:\\n\", generated_poem)"]}]}